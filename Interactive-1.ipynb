{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599cac77-01b7-40bf-ba1c-2776eec2387b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflite_runtime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mevog-id\\project-bodypix\\pose_engine.py:24\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mPIL\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtflite_runtime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpreter\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m load_delegate\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtflite_runtime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpreter\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Interpreter\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpycoral\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39madapters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m output_tensor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tflite_runtime'"
     ]
    }
   ],
   "source": [
    "# Copyright 2019 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tflite_runtime.interpreter import load_delegate\n",
    "from tflite_runtime.interpreter import Interpreter\n",
    "\n",
    "from pycoral.adapters.common import output_tensor\n",
    "from pycoral.utils.edgetpu import run_inference\n",
    "\n",
    "EDGETPU_SHARED_LIB = 'libedgetpu.so.1'\n",
    "POSENET_SHARED_LIB = os.path.join(\n",
    "    'posenet_lib', os.uname().machine, 'posenet_decoder.so')\n",
    "\n",
    "EDGES = (\n",
    "    ('nose', 'left eye'),\n",
    "    ('nose', 'right eye'),\n",
    "    ('nose', 'left ear'),\n",
    "    ('nose', 'right ear'),\n",
    "    ('left ear', 'left eye'),\n",
    "    ('right ear', 'right eye'),\n",
    "    ('left eye', 'right eye'),\n",
    "    ('left shoulder', 'right shoulder'),\n",
    "    ('left shoulder', 'left elbow'),\n",
    "    ('left shoulder', 'left hip'),\n",
    "    ('right shoulder', 'right elbow'),\n",
    "    ('right shoulder', 'right hip'),\n",
    "    ('left elbow', 'left wrist'),\n",
    "    ('right elbow', 'right wrist'),\n",
    "    ('left hip', 'right hip'),\n",
    "    ('left hip', 'left knee'),\n",
    "    ('right hip', 'right knee'),\n",
    "    ('left knee', 'left ankle'),\n",
    "    ('right knee', 'right ankle'),\n",
    ")\n",
    "\n",
    "KEYPOINTS = (\n",
    "  'nose',\n",
    "  'left eye',\n",
    "  'right eye',\n",
    "  'left ear',\n",
    "  'right ear',\n",
    "  'left shoulder',\n",
    "  'right shoulder',\n",
    "  'left elbow',\n",
    "  'right elbow',\n",
    "  'left wrist',\n",
    "  'right wrist',\n",
    "  'left hip',\n",
    "  'right hip',\n",
    "  'left knee',\n",
    "  'right knee',\n",
    "  'left ankle',\n",
    "  'right ankle'\n",
    ")\n",
    "\n",
    "BODYPIX_PARTS = {\n",
    "  0: \"left face\",\n",
    "  1: \"right face\",\n",
    "  2: \"left upper arm front\",\n",
    "  3: \"left upper arm back\",\n",
    "  4: \"right upper arm front\",\n",
    "  5: \"right upper arm back\",\n",
    "  6: \"left lower arm front\",\n",
    "  7: \"left lower arm back\",\n",
    "  8: \"right lower arm front\",\n",
    "  9: \"right lower arm back\",\n",
    "  10: \"left hand\",\n",
    "  11: \"right hand\",\n",
    "  12:  \"torso front\",\n",
    "  13:  \"torso back\",\n",
    "  14:  \"left upper leg front\",\n",
    "  15:  \"left upper leg back\",\n",
    "  16:  \"right upper leg front\",\n",
    "  17:  \"right upper leg back\",\n",
    "  18:  \"left lower leg front\",\n",
    "  19:  \"left lower leg back\",\n",
    "  20:  \"right lower leg front\",\n",
    "  21:  \"right lower leg back\",\n",
    "  22:  \"left feet\",\n",
    "  23:  \"right feet\",\n",
    "}\n",
    "\n",
    "class Keypoint:\n",
    "    __slots__ = ['k', 'yx', 'score']\n",
    "\n",
    "    def __init__(self, k, yx, score=None):\n",
    "        self.k = k\n",
    "        self.yx = yx\n",
    "        self.score = score\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Keypoint(<{}>, {}, {})'.format(KEYPOINTS[self.k], self.yx, self.score)\n",
    "\n",
    "\n",
    "class Pose:\n",
    "    __slots__ = ['keypoints', 'score']\n",
    "\n",
    "    def __init__(self, keypoints, score=None):\n",
    "        assert len(keypoints) == len(KEYPOINTS)\n",
    "        self.keypoints = keypoints\n",
    "        self.score = score\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Pose({}, {})'.format(self.keypoints, self.score)\n",
    "\n",
    "\n",
    "class PoseEngine:\n",
    "    \"\"\"Engine used for pose tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, model_path, mirror=False):\n",
    "        \"\"\"Creates a PoseEngine with given model.\n",
    "\n",
    "        Args:\n",
    "          model_path: String, path to TF-Lite Flatbuffer file.\n",
    "          mirror: Flip keypoints horizontally\n",
    "\n",
    "        Raises:\n",
    "          ValueError: An error occurred when model output is invalid.\n",
    "        \"\"\"\n",
    "        self._mirror = mirror\n",
    "\n",
    "        edgetpu_delegate = load_delegate(EDGETPU_SHARED_LIB)\n",
    "        posenet_decoder_delegate = load_delegate(POSENET_SHARED_LIB)\n",
    "        self._interpreter = Interpreter(\n",
    "            model_path, experimental_delegates=[edgetpu_delegate, posenet_decoder_delegate])\n",
    "        self._interpreter.allocate_tensors()\n",
    "        self._input_tensor_shape = self._interpreter.get_input_details()[0]['shape']\n",
    "        if (self._input_tensor_shape.size != 4 or\n",
    "                self._input_tensor_shape[3] != 3 or\n",
    "                self._input_tensor_shape[0] != 1):\n",
    "            raise ValueError(\n",
    "                ('Image model should have input shape [1, height, width, 3]!'\n",
    "                 ' This model has {}.'.format(self._input_tensor_shape)))\n",
    "        _, self.image_height, self.image_width, self.image_depth = self._input_tensor_shape\n",
    "\n",
    "\n",
    "        # Auto-detect stride size\n",
    "        def calcStride(h,w,L):\n",
    "          return int((2*h*w)/(math.sqrt(h**2 + 4*h*L*w - 2*h*w + w**2) - h - w))\n",
    "\n",
    "        details = self._interpreter.get_output_details()[5]\n",
    "        self.heatmap_zero_point = details['quantization_parameters']['zero_points'][0]\n",
    "        self.heatmap_scale = details['quantization_parameters']['scales'][0]\n",
    "        heatmap_size = self._interpreter.tensor(details['index'])().nbytes\n",
    "        self.stride = calcStride(self.image_height, self.image_width, heatmap_size)\n",
    "        self.heatmap_size = (self.image_width // self.stride + 1, self.image_height // self.stride + 1)\n",
    "        details = self._interpreter.get_output_details()[6]\n",
    "        self.parts_zero_point = details['quantization_parameters']['zero_points'][0]\n",
    "        self.parts_scale = details['quantization_parameters']['scales'][0]\n",
    "\n",
    "        print(\"Heatmap size: \", self.heatmap_size)\n",
    "        print(\"Stride: \", self.stride, self.heatmap_size)\n",
    "\n",
    "\n",
    "    def DetectPosesInImage(self, img):\n",
    "        \"\"\"Detects poses in a given image.\n",
    "\n",
    "           For ideal results make sure the image fed to this function is close to the\n",
    "           expected input size - it is the caller's responsibility to resize the\n",
    "           image accordingly.\n",
    "\n",
    "        Args:\n",
    "          img: numpy array containing image\n",
    "        \"\"\"\n",
    "\n",
    "        # Extend or crop the input to match the input shape of the network.\n",
    "        if img.shape[0] < self.image_height or img.shape[1] < self.image_width:\n",
    "            pads = [[0, max(0, self.image_height - img.shape[0])],\n",
    "                    [0, max(0, self.image_width - img.shape[1])], [0, 0]]\n",
    "            img = np.pad(img, pads, mode='constant')\n",
    "        img = img[0:self.image_height, 0:self.image_width]\n",
    "        assert (img.shape == tuple(self._input_tensor_shape[1:]))\n",
    "\n",
    "        # Run the inference (API expects the data to be flattened)\n",
    "        inference_time, outputs = self.run_inference(img.flatten())\n",
    "        poses = self._parse_poses(outputs)\n",
    "        heatmap, bodyparts = self._parse_heatmaps(outputs)\n",
    "        return inference_time, poses, heatmap, bodyparts\n",
    "\n",
    "    def DetectPosesInTensor(self, tensor):\n",
    "        inference_time, output = self.run_inference(tensor)\n",
    "        poses = self._parse_poses(output)\n",
    "        heatmap, bodyparts = self._parse_heatmaps(output)\n",
    "        return inference_time, poses, heatmap, bodyparts\n",
    "\n",
    "    def ParseOutputs(self, outputs):\n",
    "        poses = self._parse_poses(outputs)\n",
    "        heatmap, bodyparts = self._parse_heatmaps(outputs)\n",
    "        return poses, heatmap, bodyparts\n",
    "\n",
    "    def _parse_poses(self, outputs):\n",
    "        keypoints = outputs[0].reshape(-1, len(KEYPOINTS), 2)\n",
    "        keypoint_scores = outputs[1].reshape(-1, len(KEYPOINTS))\n",
    "        pose_scores = outputs[2].flatten()\n",
    "        nposes = int(outputs[3][0])\n",
    "\n",
    "        # Convert the poses to a friendlier format of keypoints with associated\n",
    "        # scores.\n",
    "        poses = []\n",
    "        for pose_i in range(nposes):\n",
    "            keypoint_dict = {}\n",
    "            for point_i, point in enumerate(keypoints[pose_i]):\n",
    "                keypoint = Keypoint(KEYPOINTS[point_i], point,\n",
    "                                    keypoint_scores[pose_i, point_i])\n",
    "                if self._mirror: keypoint.yx[1] = self.image_width - keypoint.yx[1]\n",
    "                keypoint_dict[KEYPOINTS[point_i]] = keypoint\n",
    "            poses.append(Pose(keypoint_dict, pose_scores[pose_i]))\n",
    "\n",
    "        return poses\n",
    "\n",
    "    def softmax(self, y, axis):\n",
    "        y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "        y = np.exp(y)\n",
    "        return y / np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "\n",
    "    def _parse_heatmaps(self, outputs):\n",
    "        # Heatmaps are really float32.\n",
    "        heatmap = (outputs[5].astype(np.float32) - self.heatmap_zero_point) * self.heatmap_scale\n",
    "        heatmap = np.reshape(heatmap, [self.heatmap_size[1], self.heatmap_size[0]])\n",
    "        part_heatmap = (outputs[6].astype(np.float32) - self.parts_zero_point) * self.parts_scale\n",
    "        part_heatmap = np.reshape(part_heatmap, [self.heatmap_size[1], self.heatmap_size[0], -1])\n",
    "        part_heatmap = self.softmax(part_heatmap, axis=2)\n",
    "        return heatmap, part_heatmap\n",
    "\n",
    "    def run_inference(self, input):\n",
    "        start_time = time.monotonic()\n",
    "        run_inference(self._interpreter, input)\n",
    "        duration_ms = (time.monotonic() - start_time) * 1000\n",
    "\n",
    "        output = []\n",
    "        for details in self._interpreter.get_output_details():\n",
    "            tensor = self._interpreter.get_tensor(details['index'])\n",
    "            output.append(tensor)\n",
    "\n",
    "        return (duration_ms, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a40af5-a360-481a-96eb-a8c37f22bb02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflite_runtime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mevog-id\\project-bodypix\\pose_engine.py:24\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mPIL\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Image\n\u001b[1;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtflite_runtime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpreter\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m Interpreter\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mtflite_runtime\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minterpreter\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m load_delegate\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpycoral\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39madapters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m output_tensor\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tflite_runtime'"
     ]
    }
   ],
   "source": [
    "# Copyright 2019 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tflite_runtime.interpreter import Interpreter\n",
    "from tflite_runtime.interpreter import load_delegate\n",
    "\n",
    "\n",
    "from pycoral.adapters.common import output_tensor\n",
    "from pycoral.utils.edgetpu import run_inference\n",
    "\n",
    "EDGETPU_SHARED_LIB = 'libedgetpu.so.1'\n",
    "POSENET_SHARED_LIB = os.path.join(\n",
    "    'posenet_lib', os.uname().machine, 'posenet_decoder.so')\n",
    "\n",
    "EDGES = (\n",
    "    ('nose', 'left eye'),\n",
    "    ('nose', 'right eye'),\n",
    "    ('nose', 'left ear'),\n",
    "    ('nose', 'right ear'),\n",
    "    ('left ear', 'left eye'),\n",
    "    ('right ear', 'right eye'),\n",
    "    ('left eye', 'right eye'),\n",
    "    ('left shoulder', 'right shoulder'),\n",
    "    ('left shoulder', 'left elbow'),\n",
    "    ('left shoulder', 'left hip'),\n",
    "    ('right shoulder', 'right elbow'),\n",
    "    ('right shoulder', 'right hip'),\n",
    "    ('left elbow', 'left wrist'),\n",
    "    ('right elbow', 'right wrist'),\n",
    "    ('left hip', 'right hip'),\n",
    "    ('left hip', 'left knee'),\n",
    "    ('right hip', 'right knee'),\n",
    "    ('left knee', 'left ankle'),\n",
    "    ('right knee', 'right ankle'),\n",
    ")\n",
    "\n",
    "KEYPOINTS = (\n",
    "  'nose',\n",
    "  'left eye',\n",
    "  'right eye',\n",
    "  'left ear',\n",
    "  'right ear',\n",
    "  'left shoulder',\n",
    "  'right shoulder',\n",
    "  'left elbow',\n",
    "  'right elbow',\n",
    "  'left wrist',\n",
    "  'right wrist',\n",
    "  'left hip',\n",
    "  'right hip',\n",
    "  'left knee',\n",
    "  'right knee',\n",
    "  'left ankle',\n",
    "  'right ankle'\n",
    ")\n",
    "\n",
    "BODYPIX_PARTS = {\n",
    "  0: \"left face\",\n",
    "  1: \"right face\",\n",
    "  2: \"left upper arm front\",\n",
    "  3: \"left upper arm back\",\n",
    "  4: \"right upper arm front\",\n",
    "  5: \"right upper arm back\",\n",
    "  6: \"left lower arm front\",\n",
    "  7: \"left lower arm back\",\n",
    "  8: \"right lower arm front\",\n",
    "  9: \"right lower arm back\",\n",
    "  10: \"left hand\",\n",
    "  11: \"right hand\",\n",
    "  12:  \"torso front\",\n",
    "  13:  \"torso back\",\n",
    "  14:  \"left upper leg front\",\n",
    "  15:  \"left upper leg back\",\n",
    "  16:  \"right upper leg front\",\n",
    "  17:  \"right upper leg back\",\n",
    "  18:  \"left lower leg front\",\n",
    "  19:  \"left lower leg back\",\n",
    "  20:  \"right lower leg front\",\n",
    "  21:  \"right lower leg back\",\n",
    "  22:  \"left feet\",\n",
    "  23:  \"right feet\",\n",
    "}\n",
    "\n",
    "class Keypoint:\n",
    "    __slots__ = ['k', 'yx', 'score']\n",
    "\n",
    "    def __init__(self, k, yx, score=None):\n",
    "        self.k = k\n",
    "        self.yx = yx\n",
    "        self.score = score\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Keypoint(<{}>, {}, {})'.format(KEYPOINTS[self.k], self.yx, self.score)\n",
    "\n",
    "\n",
    "class Pose:\n",
    "    __slots__ = ['keypoints', 'score']\n",
    "\n",
    "    def __init__(self, keypoints, score=None):\n",
    "        assert len(keypoints) == len(KEYPOINTS)\n",
    "        self.keypoints = keypoints\n",
    "        self.score = score\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Pose({}, {})'.format(self.keypoints, self.score)\n",
    "\n",
    "\n",
    "class PoseEngine:\n",
    "    \"\"\"Engine used for pose tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, model_path, mirror=False):\n",
    "        \"\"\"Creates a PoseEngine with given model.\n",
    "\n",
    "        Args:\n",
    "          model_path: String, path to TF-Lite Flatbuffer file.\n",
    "          mirror: Flip keypoints horizontally\n",
    "\n",
    "        Raises:\n",
    "          ValueError: An error occurred when model output is invalid.\n",
    "        \"\"\"\n",
    "        self._mirror = mirror\n",
    "\n",
    "        edgetpu_delegate = load_delegate(EDGETPU_SHARED_LIB)\n",
    "        posenet_decoder_delegate = load_delegate(POSENET_SHARED_LIB)\n",
    "        self._interpreter = Interpreter(\n",
    "            model_path, experimental_delegates=[edgetpu_delegate, posenet_decoder_delegate])\n",
    "        self._interpreter.allocate_tensors()\n",
    "        self._input_tensor_shape = self._interpreter.get_input_details()[0]['shape']\n",
    "        if (self._input_tensor_shape.size != 4 or\n",
    "                self._input_tensor_shape[3] != 3 or\n",
    "                self._input_tensor_shape[0] != 1):\n",
    "            raise ValueError(\n",
    "                ('Image model should have input shape [1, height, width, 3]!'\n",
    "                 ' This model has {}.'.format(self._input_tensor_shape)))\n",
    "        _, self.image_height, self.image_width, self.image_depth = self._input_tensor_shape\n",
    "\n",
    "\n",
    "        # Auto-detect stride size\n",
    "        def calcStride(h,w,L):\n",
    "          return int((2*h*w)/(math.sqrt(h**2 + 4*h*L*w - 2*h*w + w**2) - h - w))\n",
    "\n",
    "        details = self._interpreter.get_output_details()[5]\n",
    "        self.heatmap_zero_point = details['quantization_parameters']['zero_points'][0]\n",
    "        self.heatmap_scale = details['quantization_parameters']['scales'][0]\n",
    "        heatmap_size = self._interpreter.tensor(details['index'])().nbytes\n",
    "        self.stride = calcStride(self.image_height, self.image_width, heatmap_size)\n",
    "        self.heatmap_size = (self.image_width // self.stride + 1, self.image_height // self.stride + 1)\n",
    "        details = self._interpreter.get_output_details()[6]\n",
    "        self.parts_zero_point = details['quantization_parameters']['zero_points'][0]\n",
    "        self.parts_scale = details['quantization_parameters']['scales'][0]\n",
    "\n",
    "        print(\"Heatmap size: \", self.heatmap_size)\n",
    "        print(\"Stride: \", self.stride, self.heatmap_size)\n",
    "\n",
    "\n",
    "    def DetectPosesInImage(self, img):\n",
    "        \"\"\"Detects poses in a given image.\n",
    "\n",
    "           For ideal results make sure the image fed to this function is close to the\n",
    "           expected input size - it is the caller's responsibility to resize the\n",
    "           image accordingly.\n",
    "\n",
    "        Args:\n",
    "          img: numpy array containing image\n",
    "        \"\"\"\n",
    "\n",
    "        # Extend or crop the input to match the input shape of the network.\n",
    "        if img.shape[0] < self.image_height or img.shape[1] < self.image_width:\n",
    "            pads = [[0, max(0, self.image_height - img.shape[0])],\n",
    "                    [0, max(0, self.image_width - img.shape[1])], [0, 0]]\n",
    "            img = np.pad(img, pads, mode='constant')\n",
    "        img = img[0:self.image_height, 0:self.image_width]\n",
    "        assert (img.shape == tuple(self._input_tensor_shape[1:]))\n",
    "\n",
    "        # Run the inference (API expects the data to be flattened)\n",
    "        inference_time, outputs = self.run_inference(img.flatten())\n",
    "        poses = self._parse_poses(outputs)\n",
    "        heatmap, bodyparts = self._parse_heatmaps(outputs)\n",
    "        return inference_time, poses, heatmap, bodyparts\n",
    "\n",
    "    def DetectPosesInTensor(self, tensor):\n",
    "        inference_time, output = self.run_inference(tensor)\n",
    "        poses = self._parse_poses(output)\n",
    "        heatmap, bodyparts = self._parse_heatmaps(output)\n",
    "        return inference_time, poses, heatmap, bodyparts\n",
    "\n",
    "    def ParseOutputs(self, outputs):\n",
    "        poses = self._parse_poses(outputs)\n",
    "        heatmap, bodyparts = self._parse_heatmaps(outputs)\n",
    "        return poses, heatmap, bodyparts\n",
    "\n",
    "    def _parse_poses(self, outputs):\n",
    "        keypoints = outputs[0].reshape(-1, len(KEYPOINTS), 2)\n",
    "        keypoint_scores = outputs[1].reshape(-1, len(KEYPOINTS))\n",
    "        pose_scores = outputs[2].flatten()\n",
    "        nposes = int(outputs[3][0])\n",
    "\n",
    "        # Convert the poses to a friendlier format of keypoints with associated\n",
    "        # scores.\n",
    "        poses = []\n",
    "        for pose_i in range(nposes):\n",
    "            keypoint_dict = {}\n",
    "            for point_i, point in enumerate(keypoints[pose_i]):\n",
    "                keypoint = Keypoint(KEYPOINTS[point_i], point,\n",
    "                                    keypoint_scores[pose_i, point_i])\n",
    "                if self._mirror: keypoint.yx[1] = self.image_width - keypoint.yx[1]\n",
    "                keypoint_dict[KEYPOINTS[point_i]] = keypoint\n",
    "            poses.append(Pose(keypoint_dict, pose_scores[pose_i]))\n",
    "\n",
    "        return poses\n",
    "\n",
    "    def softmax(self, y, axis):\n",
    "        y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "        y = np.exp(y)\n",
    "        return y / np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "\n",
    "    def _parse_heatmaps(self, outputs):\n",
    "        # Heatmaps are really float32.\n",
    "        heatmap = (outputs[5].astype(np.float32) - self.heatmap_zero_point) * self.heatmap_scale\n",
    "        heatmap = np.reshape(heatmap, [self.heatmap_size[1], self.heatmap_size[0]])\n",
    "        part_heatmap = (outputs[6].astype(np.float32) - self.parts_zero_point) * self.parts_scale\n",
    "        part_heatmap = np.reshape(part_heatmap, [self.heatmap_size[1], self.heatmap_size[0], -1])\n",
    "        part_heatmap = self.softmax(part_heatmap, axis=2)\n",
    "        return heatmap, part_heatmap\n",
    "\n",
    "    def run_inference(self, input):\n",
    "        start_time = time.monotonic()\n",
    "        run_inference(self._interpreter, input)\n",
    "        duration_ms = (time.monotonic() - start_time) * 1000\n",
    "\n",
    "        output = []\n",
    "        for details in self._interpreter.get_output_details():\n",
    "            tensor = self._interpreter.get_tensor(details['index'])\n",
    "            output.append(tensor)\n",
    "\n",
    "        return (duration_ms, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
